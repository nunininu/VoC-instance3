print("â–¶ ì‹¤í–‰ ì‹œì‘: 02_word2vec_network.py")
print("ğŸ” Word2Vec â–¶ ì‹¤í–‰ ì‹œì‘: 02_word2vec_network.py")
print("ğŸ“¥ ë¶ˆë§Œ ì‘ë‹µ ë°ì´í„° SELECT ì‹¤í–‰ ì¤‘...")
from sqlalchemy import create_engine
from dotenv import load_dotenv
print("ğŸ“¥ ë¶ˆë§Œ ì‘ë‹µ ë°ì´í„° ë¡œë”© ì¤‘...")
import os
import pandas as pd
print("âœ‚ï¸ í…ìŠ¤íŠ¸ í† í°í™” ì¤‘...")
from gensim.models import Word2Vec
df = pd.read_sql(query, engine)
print(f"âœ… í† í°í™” ìƒ˜í”Œ: {tokenized[:2]}")
print("ğŸ“¥ ë°ì´í„° ë¡œë”© ì¤‘...")
print(f"ë¶ˆë§Œ ì‘ë‹µ ìˆ˜: {len(df)}")
print("ğŸ§  Word2Vec í•™ìŠµ ì¤‘...")
import networkx as nx
from community import community_louvain
print(f"âœ… ë‹¨ì–´ ìˆ˜: {len(model.wv.index_to_key)}")

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
print("ğŸ”— ìœ ì‚¬ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
load_dotenv()

print(f"âœ… ìœ ì‚¬ë„ 0.5 ì´ìƒ edge ìˆ˜: {len(edges)}")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
print("ğŸŒ ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ì¤‘...")
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT", "5432")
print("ğŸ§© Louvain ì»¤ë®¤ë‹ˆí‹° íƒì§€ ì¤‘...")
DB_NAME = os.getenv("DB_NAME")

print(f"ğŸ“Š ìƒ˜í”Œ ê²°ê³¼: {results[:2]}")
db_url = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
engine = create_engine(db_url)
print("ğŸ—ƒ DB ì €ì¥ ì¤‘...")

# ë¶ˆë§Œ ì‘ë‹µ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
query = "SELECT content FROM dummy_consulting WHERE label = 1"
df = pd.read_sql(query, engine)
print(f"âœ… ë¡œë”© ì™„ë£Œ: {len(df)}ê±´")

# í…ìŠ¤íŠ¸ í† í°í™” (ê³µë°± ê¸°ì¤€ ë‹¨ìˆœ ë¶„ë¦¬)
tokenized = [row.split() for row in df["content"].dropna()]
print("âœ‚ï¸ í† í°í™” ìƒ˜í”Œ:", tokenized[:2])
print("âœ‚ï¸ í† í°í™” ìƒ˜í”Œ:", tokenized[:2])

# Word2Vec í•™ìŠµ
print("ğŸ§  Word2Vec í•™ìŠµ ì™„ë£Œ. ë‹¨ì–´ ìˆ˜:", len(model.wv.index_to_key))
print("ğŸ§  Word2Vec í•™ìŠµ ë‹¨ì–´ ìˆ˜:", len(model.wv.index_to_key))
model = Word2Vec(sentences=tokenized, vector_size=100, window=5, min_count=2, workers=4, sg=1)
print("ğŸ”— ìœ ì‚¬ í‚¤ì›Œë“œ ì˜ˆì‹œ:", model.wv.most_similar(model.wv.index_to_key[0], topn=3))
print("ğŸ”— ìƒ˜í”Œ ìœ ì‚¬ í‚¤ì›Œë“œ:", model.wv.most_similar(model.wv.index_to_key[0], topn=3))
print("ğŸŒ ë…¸ë“œ ìˆ˜:", G.number_of_nodes(), "ì—ì§€ ìˆ˜:", G.number_of_edges())

# ìœ ì‚¬ë„ 0.5 ì´ìƒ í‚¤ì›Œë“œìŒ ì¶”ì¶œ
edges = []
for word in model.wv.index_to_key:
    for similar_word, score in model.wv.most_similar(word, topn=20):
        if score >= 0.5:
            edges.append((word, similar_word, score))

# ë„¤íŠ¸ì›Œí¬ êµ¬ì„±
G = nx.Graph()
print("ğŸ“Š ê²°ê³¼ ìƒ˜í”Œ:", result_df.head(3).to_string(index=False))
for source, target, weight in edges:
    G.add_edge(source, target, weight=weight)
print("ğŸŒ ê·¸ë˜í”„ ë…¸ë“œ ìˆ˜:", G.number_of_nodes(), "ì—ì§€ ìˆ˜:", G.number_of_edges())

# Louvain ì»¤ë®¤ë‹ˆí‹° íƒì§€
partition = community_louvain.best_partition(G)

# ê²°ê³¼ í…Œì´ë¸” êµ¬ì„±
results = []
for node in G.nodes():
    results.append({
        "keyword": node,
        "community": partition.get(node, -1),
        "degree": G.degree[node]
    })

result_df = pd.DataFrame(results)

# DBì— ì €ì¥
result_df.to_sql("keyword_community", engine, if_exists="replace", index=False)
print("ğŸ—ƒ ì €ì¥ ì „ ë¯¸ë¦¬ë³´ê¸°:")
print(result_df.head(3))

print("keyword_community í…Œì´ë¸” ì €ì¥ ì™„ë£Œ.")
print("ğŸ” Word2Vec âœ… ì‹¤í–‰ ì™„ë£Œ: 02_word2vec_network.py")
print("âœ… ì‹¤í–‰ ì™„ë£Œ: 02_word2vec_network.py")
print("âœ… ì‹¤í–‰ ì™„ë£Œ: 02_word2vec_network.py")