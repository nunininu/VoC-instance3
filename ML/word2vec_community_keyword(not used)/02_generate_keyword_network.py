import pandas as pd
import numpy as np
from sqlalchemy import create_engine
from gensim.models import Word2Vec
import networkx as nx
import pyvis.network
from sklearn.preprocessing import MinMaxScaler
from dotenv import load_dotenv
import os
from community import community_louvain
from jinja2 import Template

# í…œí”Œë¦¿ ë¡œë“œ ë° ì¸ìŠ¤í„´ìŠ¤ì— ì§ì ‘ í• ë‹¹
template_path = os.path.join(os.path.dirname(pyvis.network.__file__), "templates", "template.html")
with open(template_path, "r", encoding="utf-8") as f:
    html_template = Template(f.read())

print("ğŸ“¦ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì¤‘...")
os.environ.clear()  # ìºì‹œëœ ì˜ëª»ëœ í™˜ê²½ë³€ìˆ˜ ì´ˆê¸°í™”
load_dotenv(dotenv_path=".env", override=True)

DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME")

engine = create_engine(f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}")

# Step 1: í‚¤ì›Œë“œ ë¶ˆëŸ¬ì˜¤ê¸°
print("ğŸ“¥ í‚¤ì›Œë“œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
query = "SELECT keywords FROM dummy_analysis_result WHERE keywords IS NOT NULL AND keywords != ''"
df = pd.read_sql(query, engine)
documents = [row.split() for row in df["keywords"]]

# Step 2: Word2Vec í›ˆë ¨
print("ğŸ§  Word2Vec í›ˆë ¨ ì¤‘...")
model = Word2Vec(sentences=documents, vector_size=100, window=5, min_count=1, workers=4)

# Step 3: ìœ ì‚¬ë„ ê¸°ë°˜ ì—£ì§€ ì¶”ì¶œ
print("ğŸ”— ì—£ì§€ êµ¬ì„± ì¤‘...")
edges = []
vocab = list(model.wv.index_to_key)
for i, word1 in enumerate(vocab):
    for word2 in vocab[i+1:]:
        sim = model.wv.similarity(word1, word2)
        if sim > 0.6:
            edges.append((word1, word2, sim))

# Step 4: NetworkX ê·¸ë˜í”„ ìƒì„± ë° ì¤‘ì‹¬ì„± ê³„ì‚°
print("ğŸŒ ê·¸ë˜í”„ êµ¬ì„± ì¤‘...")
G = nx.Graph()
G.add_weighted_edges_from(edges)
centrality = nx.degree_centrality(G)
scaled = MinMaxScaler().fit_transform(np.array(list(centrality.values())).reshape(-1,1)).reshape(-1)
centrality_scaled = dict(zip(centrality.keys(), scaled))

# Step 5: ì»¤ë®¤ë‹ˆí‹° ë¼ë²¨ë§
print("ğŸ§© ì»¤ë®¤ë‹ˆí‹° íƒì§€ ì¤‘...")
partition = community_louvain.best_partition(G)


# Step 6: PyVis ì‹œê°í™”
print("ğŸ–¼ï¸ ì‹œê°í™” êµ¬ì„± ì¤‘...")
net = pyvis.network.Network(height="800px", width="100%", bgcolor="#222222", font_color="white", notebook=False)
net.template = html_template  # ì¸ìŠ¤í„´ìŠ¤ì— ì§ì ‘ í• ë‹¹
net.force_atlas_2based()

for node in G.nodes():
    net.add_node(
        node,
        label=node,
        title=f"ì»¤ë®¤ë‹ˆí‹°: {partition[node]}\\nì¤‘ì‹¬ì„±: {float(centrality_scaled[node]):.4f}",
        color=f"hsl({partition[node]*37 % 360}, 80%, 60%)",
        value=float(centrality_scaled[node])  # float32 â†’ float
    )

for source, target, weight in edges:
    net.add_edge(source, target, value=float(weight))  # float32 â†’ float

# ì˜¤ë¥˜ íšŒí”¼ë¥¼ ìœ„í•œ ìˆ˜ë™ HTML ì €ì¥
html = net.generate_html()
with open("force_directed_keyword_graph.html", "w", encoding="utf-8") as f:
    f.write(html)

print("âœ… force_directed_keyword_graph.html ìƒì„± ì™„ë£Œ")
