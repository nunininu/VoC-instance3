from sqlalchemy import create_engine
from dotenv import load_dotenv
import pandas as pd
import os
from gensim.models import Word2Vec
import networkx as nx
from community import community_louvain

print("â–¶ Word2Vec ë„¤íŠ¸ì›Œí¬ + ì»¤ë®¤ë‹ˆí‹° í†µí•© ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME")
db_url = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
engine = create_engine(db_url)
print("âœ… DB ì—°ê²° ì™„ë£Œ")

# ë¶ˆë§Œ ì‘ë‹µ ë¡œë”©
df = pd.read_sql("SELECT content FROM dummy_consulting WHERE label = 1", engine)
print(f"ğŸ“¥ ë¶ˆë§Œ ì‘ë‹µ {len(df)}ê±´ ë¡œë”© ì™„ë£Œ")

# í† í°í™”
tokenized = [row.split() for row in df["content"].dropna()]
print("âœ‚ï¸ í† í°í™” ì™„ë£Œ")

# Word2Vec í•™ìŠµ
model = Word2Vec(sentences=tokenized, vector_size=100, window=5, min_count=2, workers=4, sg=1)
print(f"ğŸ§  Word2Vec í•™ìŠµ ì™„ë£Œ (ë‹¨ì–´ ìˆ˜: {len(model.wv.index_to_key)})")

# sim â‰¥ 0.5 edge ì¶”ì¶œ
edges = []
for word in model.wv.index_to_key:
    for similar_word, score in model.wv.most_similar(word, topn=20):
        if score >= 0.5:
            edges.append((word, similar_word, score))
print(f"ğŸ”— ìœ ì‚¬ë„ í•„í„°ë§ í›„ edge ìˆ˜: {len(edges)}")

# DataFrame ìƒì„±
df_edges = pd.DataFrame(edges, columns=["source", "target", "weight"])

# ìê¸°ì°¸ì¡° ì œê±°
df_edges = df_edges[df_edges["source"] != df_edges["target"]]

# ë¬´ë°©í–¥ ì¤‘ë³µ ì œê±°
df_edges["pair"] = df_edges.apply(lambda row: tuple(sorted([row["source"], row["target"]])), axis=1)
df_edges = df_edges.drop_duplicates(subset="pair").drop(columns=["pair"])
print(f"ğŸ§¹ ì¤‘ë³µ ì œê±° í›„ edge ìˆ˜: {len(df_edges)}")

# Top-K í•„í„°ë§
TOP_K = 300
df_edges = df_edges.sort_values(by="weight", ascending=False).head(TOP_K)
print(f"ğŸ¯ Top-{TOP_K} edge ì¶”ì¶œ ì™„ë£Œ")

# keyword_edge_final ì €ì¥
df_edges.to_sql("keyword_edge_final", engine, if_exists="replace", index=False)
df_edges.to_csv("keyword_edge_final.csv", index=False)
print("ğŸ“¤ keyword_edge_final ì €ì¥ ì™„ë£Œ")

# ì»¤ë®¤ë‹ˆí‹° íƒì§€
G = nx.Graph()
for source, target, weight in df_edges.values:
    G.add_edge(source, target, weight=weight)

partition = community_louvain.best_partition(G)

# ë…¸ë“œë³„ community ì €ì¥
node_records = []
for node in G.nodes():
    node_records.append({
        "keyword": node,
        "community": partition.get(node, -1),
        "degree": G.degree[node]
    })

df_community = pd.DataFrame(node_records)
df_community.to_sql("keyword_community_final", engine, if_exists="replace", index=False)
df_community.to_csv("keyword_community_final.csv", index=False)
print("ğŸ“¤ keyword_community_final ì €ì¥ ì™„ë£Œ")

print("âœ… ì‹¤í–‰ ì™„ë£Œ: Word2Vec ë„¤íŠ¸ì›Œí¬ + ì»¤ë®¤ë‹ˆí‹° í†µí•©")
